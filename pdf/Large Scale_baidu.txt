基于深卷积激活特征的大规模组织病理图像分类、分割和可视化
严旭1，2*，志鹏佳2，3，梁伯望2，4，余庆爱2，3，方丈2，3，茅德来5和艾瑞克·赵昌2
摘要
背景：组织病理学图像分析是肿瘤识别和诊断的金标准。组织病理图像的自动分析可以帮助病理学家诊断肿瘤和癌症亚型，减轻病理学家的工作量。数字组织病理图像分析有两种基本任务：图像分类和图像分割。阻碍自动分析的组织病理学图像的典型问题包括复杂的临床表现、数据集中有限数量的训练图像以及非常大的奇异图像（通常高达千兆像素）。对于单个图像来说，非常大尺寸的特性也使得组织病理学图像数据集被认为是大规模的，即使数据集中的图像数量有限。
结果：本文提出利用深层卷积神经网络（CNN）的激活特征对大规模组织病理图像进行分类、分割和可视化。我们的框架将从由大型自然图像数据库ImageNet训练的CNN中提取的特征传输到组织病理图像。我们还通过可视化最后隐藏层中单个神经元成分的反应来探索CNN特征的特征。这些特征中的一些揭示了病理学家已经证实的生物学见解。根据我们的实验，所提出的框架在来自MICCAI 2014 Brain Tumor.Pat.y Challenge和结肠癌组织病理学图像数据集的脑肿瘤数据集上显示了最新的性能。
结论：该框架是一种简单、高效、有效的组织病理图像自动分析系统。我们成功地将ImageNet知识作为深度卷积激活特征用于组织病理图像的分类和分割，训练数据少。美国有线电视新闻网的特点比专家设计的功能更强大。
关键词：深卷积激活特征，深层学习，特征学习，分割，分类
背景
组织病理学图像分析是癌症识别和诊断的金标准[1，2]。数字组织病理图像分析可以帮助病理学家诊断肿瘤和癌症亚型，减轻病理学家的工作量。数字组织病理图像分析有两种基本任务：图像分类和图像分割。在分类任务中，算法以整张幻灯片病理图像为输入，输出输入图像的标签。可能的标签是预先定义的，它们可以是某些类型的癌症或正常。在分割中，该算法以组织病理图像的一部分作为输入，对输入图像中具有一定特征的区域进行分割。
在这两个任务中，都给出了一组带有地面真值标签和注释的训练数据。在本文中，我们为所有相关的组织病理学问题（如分类和分割）开发了一个通用的框架，以及一个可视化方法来探索揭示关键生物学观点的深部卷积激活特征的特征。
数字组织病理图像的自动分析存在三个主要挑战：临床特征表示的复杂性、训练图像的数量不足、以及单个组织病理图像的超大尺寸。
第一个挑战反映在表现复杂的临床特征方面的困难。特征表示在医学图像分析中占有重要地位[3, 4 ]。
不同癌症类型的组织病理学可呈现显著不同的形态、规模、质地和颜色分布，这使得很难找到既适用于脑癌又适用于结肠癌的肿瘤检测的一般模式。因此，特征表示_5_在诸如分类和分割等高级医学图像任务中是非常重要的。许多以前的工作都集中在特征设计上，比如类对象[6，7]和纹理特征[8，9]。然而，其设计的特殊性限制了固定图像源的应用。
另一个主要问题是医学图像领域中的训练数据量不足。医学图像数据集的大小通常比自然场景图像数据集小得多，这使得许多以前的机器学习算法的直接应用不适合于医学图像数据集。这两个因素使得医学图像采集昂贵。一是研究疾病的发病率低。由于所研究的疾病的低频使得采集过程变得更加困难，因为图像的数量取决于疾病发生的数量。另一个是人工数据注释所需的大量劳动，因为详细手动注释医学图像通常需要大量的工作。此外，由于许多临床线索难以量化，即使由临床专家进行标记，手动注释也本质上是模糊的。
最后一个问题，个体组织病理学图像的巨大尺寸，使得组织病理学图像数据集被考虑为大规模的，并且增加了计算复杂度，从而使得图像分析更具挑战性。一个典型的整个组织病理切片可以被扫描，以产生一个大于10万×10万像素并且包含超过100万个描述对象的图像。通常，在病理切片过程中对每个患者进行12到20个扫描图像。由于组织病理学图像数据集固有的大规模特性，特征提取模型需要既具有时间效率又具有记忆效率，并且学习算法应该被设计为能够从这些大图像中提取尽可能多的信息。
在自动组织病理图像分析的所有任务中都存在上述问题。除此之外，分类和分割任务也面临着一些特殊的挑战。在分类上，不同癌症亚型之间的细微区别要求特征具有高度表达性。不同子类型实例的不平衡性也阻碍了分类器的使用。在分割任务中，需要分割的区域的定义可能是不透明的，这使得多个病理学家对基本事实的注释略有不同。这种模糊特性在分割框架的设计中成为一个挑战。
随着深卷积神经网络（CNN）的出现，CNN激活特征最近在计算机视觉领域取得了巨大的成功[10-16]。诸如ImageNet等大型可视化数据库的出现，包括1000多万幅图像和20000多个类[17]，使得CNN能够从一般图像中提供丰富和多样的特征描述。
CNN隐含层的响应提供了不同层次的图像提取，可用于提取人脸和自然场景等复杂特征。它可以从医学图像中提取足够的信息。因此，本文通过深入卷积激活，研究ImageNet知识在组织病理图像分类和分割中提取特征的潜力。
尽管CNN本身能够进行图像分类[14]和分割[18]，但是单个组织病理学图像的非常大的尺寸使得直接使用CNN进行分类或分割变得不现实。
一方面，构建具有非常大输入大小的CNN是不现实的。另一方面，将整个组织病理学图像缩放到CNN可接受的大小将丢失太多的细节信息，这使得即使对于病理学家也不可能识别。
基于这个事实，我们的分类和分割框架都采用补丁采样技术来利用小得多的局部补丁的CNN激活特征，从而保留基本的局部细节。
最后的结果采用不同的策略。在分类框架中，特征池用于构造所有幻灯片图像的特征。在分割框架中，在补丁级进行分类，并将结果用于构造图像范围的分割。更小的补丁大小和平滑被用来使边界更准确。
为了使CNN激活特征更适合于组织病理学图像，我们还对ImageNet模型进行微调，以学习捕捉复杂临床代表的更精细、更有洞察力的特征。在我们的实验中，经过微调的CNN模型可以在分类和分割任务上达到更好的精度。
此外，我们通过在组织病理图像分类中可视化4096维特征向量的各个分量来探索CNN激活特征的特征。计算每个图像的贴片置信度热图以及具有CNN激活特征的单个神经元的鉴别贴片。
热图解释了哪些斑块或区域提供了强有力的响应，使得它们的图像属于相应的类别，而代表单个神经元响应的斑块帮助我们从每个分类器的角度理解这些响应具有什么特征。通过这个可视化分析，我们发现临床知识与我们方法的反应之间的关系。
本文提出了一种简单、有效、有效的CNN激活特征用于组织病理图像分类和分割的方法。
从实验中，我们的框架实现了良好的性能在两个数据集。我们的框架的优点包括：
1。将ImageNet强大的CNN特征转换为组织病理图像的能力，解决了组织病理图像数据集训练数据量有限的问题；
2。采用斑块采样和汇聚技术利用局部描述性CNN特征，使得整个框架对非常大的整个幻灯片组织病理图像具有可伸缩性和高效性；
三。针对两种不同癌症类型的统一框架，表明了我们方法的简单性和有效性。
我们在组织病理图像自动分析领域作出了两个贡献：
1。一个通用的解决组织病理学问题的超大组织病理学图像，这证明有效和有效的两种不同类型的癌症；
2。显示我们框架所学习特征的可视化策略具有生物学洞察力，并证明CNN激活特征在表示复杂临床特征方面的能力。
徐等人提出了我们的方法的早期会议版本。〔19〕。本文进一步阐明：（1）框架方法可以应用于分析脑肿瘤以外的组织类型，如结肠癌；（2）基于ImageNet模型的微调特征；（3）引入热图来探索哪些斑块或区域提供较强的特征。在分类任务中一幅图像的响应，伴随先前单个神经响应的可视化。
相关工作
近年来，数字组织病理学的应用显示出巨大的增长。研究人员一直试图用数字组织病理学代替光学显微镜作为病理学家使用的主要工具。
在[20—23 ]中研究了各种替换方法。
在采用数字组织病理学的趋势下，已经举办了一些竞赛来促进肿瘤组织病理学研究界，包括ICPR 2012有丝分裂检测竞赛[24]、MICCAI 2013有丝分裂检测大挑战[25]、MICCAI 2014脑肿瘤数字Pa。病理学挑战[26]和MICCAI 2015腺体分割挑战赛[27]。我们提出的框架在MICCAI 2014脑肿瘤数字病理学挑战赛的分类和分割中都取得了第一名的结果[28]。
特征表示设计是关系到组织病理图像的一个重要方向。手动设计的特征包括分形特征[29]、形态计量特征[30]、纹理特征[31]和类对象特征[32]。
Kalkan[33,34]利用斑块级图像中的纹理和结构特征，提出了一种两级分类方案来区分结肠癌中的癌症和非癌症。Chang[35]提出了在不同位置和尺度上的稀疏组织形态计量学特征，以区分GBM数据集和KRIC数据集的肿瘤、坏死和向坏死过渡。由于数据量大，张还使用空间金字塔匹配来表示多尺度特征。Rashid[36]设计了两个特殊的腺体特征来描述前列腺癌中的良性和恶性腺体。细胞核层数和上皮层面积与内腔面积之比是两个特征。Song[37]使用基于学习的滤波器对图像进行变换，以获得更具代表性的特征描述符。
Sparks[38]提出了一组新的显性形状特征，以区分前列腺癌中度Gleason分级的前列腺之间的细微形状差异。Sos Agaian[39]引入了用于组织描述的新特征，如超复小波分析、四元数颜色比和改进的局部模式。
然而，这些方法的主要问题是难以选择鉴别特征来表示临床特征。研究[40]还表明，通过两层网络学习的特征比手动设计的组织病理图像表示更强大。Nayak[41]利用受限Boltzmann机器（RBM）来探索稀疏特征学习以描述透明细胞肾癌（KIRC）和GBM的组织病理学特征。这些研究表明特征学习优于特殊特征设计。但是在特征学习中，训练数据的数量在很多情况下是有限的，这已经是一个普遍的挑战。在我们的例子中，只有很少的训练图像可用于分类和分割。
使用深层CNN特征作为通用表示是许多医学图像任务的发展趋势。一些公开可用的深度CNN模型被用来提取特征：Caffe[42]在许多作品[10、11、42]中被利用，OverFeat[43]被[16]使用。这些特征通常用于分类和对象检测任务[10，11，16，42]。然而，这些研究只关注自然图像。
强大的CNN不仅能够进行分类，还能够学习特征，并且一些研究直接利用CNN的这种特性进行组织病理图像分析。Ciresan[24]将传统的CNN修改为深度最大汇集的CNN，以检测乳腺组织学图像中的有丝分裂。将检测问题转换为像素分类。从以像素为中心的贴片的信息用作上下文。他们的方法在ICPR 2012有丝分裂检测比赛中获得了第一名。训练组仅包括5张不同活检H&S染色的幻灯片，包含大约300个总有丝分裂事件。Cruz-Roa[44]提出了一种用于自动检测基底细胞癌的新型深层学习结构。该训练集包含来自皮肤组织病理学幻灯片308个感兴趣区域的1417幅图像。相比之下，ImageNet[17]由大约1400万张图像组成，这比组织病理学图像的数据集要大得多。基于对特征设计和特征学习的研究，我们决定采用由ImageNet训练的CNN特征来描述脑肿瘤和结肠癌组织病理图像中的鉴别纹理。
微调是美国有线电视新闻网学习的一个重要步骤。它保持了原有的网络体系结构，并将经过训练的CNN作为初始化处理。经过微调训练，新模型可以学习更精细的表示来描述新的目标任务。Ross[45]提出了使用微调的对象检测，使VOC 2007测试中的10%的分数从44.7%(R-CNN fc7)提高到54.2%(R-CNN.tuned fc7)。章[46 ]提出了细粒度分类。使用预训练CNN特征的准确率从68.07%提高到使用微调特征的准确率76.34%。这些研究表明，微调是有效的和高效的。在我们的例子中，基于预先训练的CNN特征，我们实施微调步骤来学习组织病理图像的更精细表示。
除了特征表示，组织病理图像分析还包括分类方案。Xu[47，48]引入了一种新的模型，称为多簇实例学习来执行组织病理学癌症图像的分类、分割和聚类。此外，Xu[49]提出了基于上下文约束的多实例学习方法。戈雷利克〔50〕提出了一种基于两级AdaBoost的分类方法。第一阶段识别组织成分，第二阶段使用所识别的组织成分来分类癌症与非癌症，以及高级别和低级别癌症。Kan.r[51]引入了一种概率分类器，它结合了多实例学习和关系学习来对癌症和非癌症进行分类。该分类器利用图像级别的信息和在不同癌症状态下细胞形成的改变。Kalman（33）提出了两阶段分类法。第一阶段将斑块分为可能的类别（腺瘤、炎症、癌症和正常）。第二阶段使用第一阶段的结果作为特征。最后，Logistic线性分类器识别癌性和非癌性。
在本例中，考虑到线性SVM分类器的简单性和快速性，我们使用了线性SVM分类器。
在分类中，所使用的输入通常是调整大小的原始图像〔14〕。提取出的CNN特征直接作为最后特征进行分类。在〔14〕中有一些不同的方法。
Sharif Razavian等人。[16]提取包括原始图像、五个农作物(原始图像区域的四个角和一个4/9的中心)以及两个旋转及其镜像的16个斑块。当使用16个补丁作为输入时，提取美国有线电视新闻网特征。之后，作者[16]将最后一层的所有响应之和作为最终特征。龚等。〔11〕在多尺度的情况下，以32像素的步长对斑块进行采样。提取深层卷积激活特征的多尺度无序池。然后，作者[11]通过局部聚集描述(VLAD)编码向量聚集局部补丁响应。在我们的方法中，受[52]的启发以及组织病理学图像非常大，高达图像的千兆像素大小的观察，我们使用补丁采样来生成许多补丁来保护详细的局部信息，并使用特征池来将补丁级别的CNN特征聚集到lAST特征。
组织病理学图像分析在广泛的研究中得到应用。可汗〔53〕提出了一种非线性染色法。图像特定颜色反卷积用于处理当使用来自不同制造商的不同组织准备、染色反应性、用户或协议以及扫描器时的颜色变化。
朱[54]提出了一种新的批量模式主动学习方法，以解决可伸缩组织病理图像分析中注释的挑战。特征选择和特征约简方案[38，55]也是组织病理图像分析中的重要步骤。
方法
美国有线电视新闻网建筑
AlexNet[14]是一种简单而通用的深层卷积神经网络，与其它类型的网络相比，在分类上仍能取得较好的性能。因此，在我们的案例中使用AlxNETS架构。本文中使用的CNN模型由ImageNet LSVRC 2013[13]的认知视觉团队共享，其结构如表1所示。它类似于[14]中使用的那个，但是没有GPU分割，因为单个现代GPU对于整个模型有足够的内存。该模型是在整个IMANET数据集上进行训练的。因此，这与ILSVRC 2013认知视觉团队使用的没有什么不同。用于训练和提取特征的代码基于[14 ]。在训练步骤中，我们使用了[14]中引入的数据预处理和数据增强方法，将不同分辨率的输入图像转换为224×224。在特征提取过程中，输入图像被调整为224×224像素，并被馈送到网络。FC2层的输出被用作提取的特征向量。
分类框架
组织病理学图像的巨大尺寸使得局部特征提取势在必行。因此，每个组织病理学图像被分成一组重叠的正方形斑块，大小分别为336×336像素的20×放大倍数和672×672像素的40×放大倍数（它们均为151872×151872nm2）。这些补丁形成具有64像素步长的矩形网格，即相邻补丁之间的距离。为了进一步减少补丁的数量，我们丢弃仅具有白色背景的补丁，其所有像素的RGB值都大于200。然后将所有选择的补丁调整到224×224像素，并馈入网络，以获得4096维CNN特征向量。在P范数池中计算图像的最终特征向量。P范数池，也称为软最大池，放大来自几个补丁的信号，这是由fP计算的，其中N是图像的补丁数，vi是第i个补丁特征向量。在我们的框架中，使用p＝3（3-范数池）。
此外，在二值分类中，为了形成更具鉴别性的特征子集，并排除冗余或不相关的特征，采用了特征选择方法。
特征选择基于正标签和负标签之间的差异。K（k）特征微分的差异由（2）计算，其中k＝1。…Npos和Nneg是训练集中的正图像和负图像的数量，vi，k是第i图像的第k维特征。然后将特征分量从最大diffk排序到最小，并选择前100个特征分量。对于多类分类，没有使用特征选择。
最后，使用线性支持向量机（SVM）。
在多类分类中，使用了一个与REST分类。图1显示了我们的分类框架的工作流程。
分割框架
医学图像分割方法一般可分为三类：监督学习[29]、弱监督[48]和无监督[32]。只有当标记数据可用时，才可使用有监督的学习方法。否则，需要其他方法（即无监督方法）。由于我们已经标记了训练数据，因此我们提出了一个有监督的学习框架用于分割。在我们的框架中，通过对一组补丁执行分类，我们将分割问题重新定义为分类问题。图2说明了我们的分割框架的工作流程。
与上述分类框架类似，在矩形网格上以8像素的步长对112×112像素的块进行采样。将112×112像素块调整为224×224像素以获得它们的CNN特征向量。线性支持向量机训练，以将所有补丁分类为正或负。由于像素可以由具有不同标签的多个重叠的补丁覆盖，所以每个像素的最终标签由覆盖该像素的补丁的多数投票决定。由于基于像素的投票提供了许多缺乏生物学意义的微小的正或负区域，因此我们利用几种平滑技术来减少区域分数。去除面积小于整个图像大小的5%的小的正和负区域。
图1分类工作流。首先，根据图像的放大倍数，在矩形网格上采样大小为336或672像素的正方形块。然后将补丁大小调整为224像素，作为我们美国有线电视新闻网模型的输入。从CNN模型中提取每个补丁的4096维特征向量。通过对每幅图像进行特征汇集和特征选择，得到100维特征。最后，线性SVM分类选定的特征。该图显示了一个二元分类，其中阳性（蓝色和橙色）和阴性（绿色）分别是脑瘤的GBM和LGG，结肠癌是癌和正常的。在多类分类中，使用了4096维的全特征向量。
在MICCAI挑战中，我们对最终提交的模型的训练数据进行了两次修改。
1。我们观察到出血组织出现在非坏死区和坏死区。因此，我们手动将坏死区域的出血斑块重新标记为非坏死斑块。这在预测阶段的测试时导致出血斑块的错误分类，但是由于这些斑块通常位于坏死区域的内部，因此可以通过后处理来校正这些误差。
2。我们观察到，训练图像是不均匀的，并且具有不同的尺寸。此外，训练数据不是均匀分布的。在最终的提交模型中，我们对训练数据的遗漏区域和错误区域的实例进行了扩充。
图2分割工作流。类似于分类工作流程，在具有8像素步长的矩形网格上采样112像素的正方形补丁。每个贴片被分配一个阳性（橙色）或阴性（蓝色）标签，这些标签是脑肿瘤中的坏死与非坏死，以及癌症与非坏死。
结肠癌正常。在训练阶段，如果一个补丁与注释的分割区域的重叠率大于0.6，则该补丁被标记为正。然后调整补丁的大小，并从我们的CNN模型中提取4096维的特征向量。线性SVM分类器用于区分阴性和阳性斑块。利用所有预测的置信度得分产生概率映射图像。平滑后，得到正分割。
数据集
我们在两个组织病理学图像数据集上对我们的分类框架和分割框架进行基准测试：MICCAI 2014脑肿瘤数字病理学挑战赛和结肠癌数据集。为了说明框架的优点，我们还对同一数据集上的其他方法和其他类型的特性进行基准测试。
对于MICCAI挑战[26]，组织者提供脑肿瘤的数字组织病理学图像数据。在分类（亚挑战I）中，目标是区分多形性胶质母细胞瘤（GBM）和低级别胶质瘤（LGG）癌。训练集有22幅LGG图像和23幅GBM图像，测试集有40幅图像。在分割（次挑战II）中，目标是从GBM组织病理图像中分离坏死区和非坏死区，因为坏死是区分LGG和GBM的重要线索。训练集包括35幅图像，测试集包括21幅图像。图像分辨率分别为502nm/像素或226nm/像素，分别对应于20×和40×源透镜的放大倍率。
对于结肠癌，H&E染色的组织病理学图像由中国浙江大学病理学系提供，并且由Hamamatsu公司的NanoZoomer幻灯片扫描仪扫描。包含典型癌症亚型特征的区域在三个组织病理学家的审查过程之后被裁剪和选择，其中两个病理学家独立地提供他们的结果，并且第三个病理学家合并和解决他们的注释中的冲突。共采集到717个种植区，最大尺度为8.51×5.66mm，平均尺度为5.10mm2。所有图像的放大倍数为40×226 nm /像素。355个癌症和362个正常图像被用于二进制任务。对于多级分类，有362个正常（N），154个腺癌（AC），44个粘液癌（MC），50个锯齿状癌（SC），38个乳头状癌（PC）和45个筛状粉刺状腺癌（CCTA）图像（总共使用了693个图像）。24个癌症图像在多类分类中被忽略，因为在它们的癌症分类中实例太少。选择半数图像作为训练数据，其他图像作为测试数据。测试数据中每个癌症亚型的比例与完整的数据集相同。在分割任务中，从数据集中选择150个训练图像和150个测试图像。它们被调整到10×放大倍率（904nm/像素），然后被裁剪到128×800像素。这是在[32 ]中使用的相同算法，用于它们的算法CGRORLM。病理学家按照前面提到的相同的回顾过程，对结肠癌图像的分割基本事实进行了注释。
实验设置
分类
为了说明CNN特征的优点，我们在我们提出的框架内将CNN特征与手动特征（具有固定提取算法）进行比较。
只修改了框架中的特征提取步骤。在我们的实验中，采用包括SIFT、LBP和L*a*b颜色直方图的通用对象识别特征（遵循[48]中的设置），并串联成总共186个特征维度。该方法用SVM-MF表示，我们提出的基于CNN特征的框架用SVM-CNN表示。
为了说明补丁采样的有效性，我们比较了我们的框架和直接使用CNN特征的方法，而不使用补丁采样。该方法将全组织病理学图像调整为224×224像素，输入CNN提取图像级特征。
然后使用线性SVM进行分类。
这种方法用SIM-IMG表示。
此外，我们比较了我们的分类框架与以往的多重聚类实例学习（MCIL）[48]和判别数据转换[37]。它们分别用McIL和Trn表示。在MCIL，补丁提取设置与我们的方法相同。这里的软最大函数是GM模型，弱分类器是高斯函数。算法的参数与原始研究相同。在TRANS中，基于学习的滤波器被应用于原始图像和特征描述符[37]。我们遵循他们原始工作中的设置（大小X=3、5、7的图像滤波器和大小Y=5的特征滤波器），并使用线性SVM作为分类器。
在所有方法中，实验采用线性支持向量机（SIM-IMG，SMS-MF，SVM CNN和反），L2正则化SVM具有线性核函数，其代价函数为1 2 WT W+C I＝1（马克斯（0, 1—YWT XI））。
使用开源工具箱LyBLID[[ 56 ] ]来优化SVM。参数C的值从{0.01，0.1，1，10，100}中选取，并通过对训练数据的交叉验证来确定最佳值。
分段
类似于分类，我们比较美国有线电视新闻网特征与手动特征。手动特征的设置与分类实验相同。该方法用SVM-MF表示，我们提出的基于CNN特征的框架用SVM-CNN表示。
为了进一步改善分割结果，对ImageNet训练的CNN模型在组织病理学图像上进行微调，以探索更适合此任务的特征。
在我们的实验中，我们将CNN的ImageNetspecific 1000路分类层替换为随机初始化的2路分类层。美国有线电视新闻网架构保持不变。我们开始学习率为0.0001的随机梯度下降（SGD）。学习速率用于未修改的层，这是ImageNet上初始预训练速率的十分之一。将CNN模型训练20个世纪，在训练过程中学习率没有下降。除了从经过微调的CNN模型中提取特征外，分割框架的其他步骤没有改变。这种方法用SVM FT表示。
此外，我们将我们的分段框架与以前的方法GraphRLM[32]进行比较。由于我们和它们的原始数据集都是具有相同放大率的结肠癌数据集，所以我们实验中的参数设置与它们出版物中给出的参数相同：rmin=8，rstrel=2，winsize=96，distthr=1.25，compthr=100。这种方法用GrimRLM表示。
线性支持向量机的设置与分类实验相同。
评价
对于分类任务，使用精度作为评价分数。对于分割任务，评估遵循MICCAI挑战的组织者提供的规则，该规则计算每个图像的重叠面积大小相对于地面真值总涉及的面积大小的比率的平均值以及由该算法预测的结果。得分的计算如下。映射定义了分配给正标签的图像i的一组像素。设图像分割的地面真值映射i为Gi，算法生成的映射为Pi。
图像i，Si的分数计算为(3)，其中K是总图像的数量。评价分数（称为精度）是SI的平均值。
对于脑肿瘤任务，由于MICCAI挑战的组织者没有提供地面真值标签和测试数据的注释，因此我们在实验中使用5倍的交叉验证进行分类，而留出一个交叉验证进行分割。此外，第2.3节中提到的修改不适用于我们自己的交叉验证实验。
结果与讨论
分类结果
在MICCAI挑战中，我们最终提交的分类任务在测试数据上达到了97.5%的准确率，在其他参与者中排名第一。表2显示了提交网站[28]中提供的一些性能最好的方法的结果。我们的结果令人满意，并且我们的性能与第二名的团队之间的差异高达7.5%，这证明我们的方法在ImageNet的帮助下即使在数据量相对较小的情况下也能达到最先进的精度。
我们比较我们的方法和最先进的方法在训练数据的MICCAI挑战。表3总结了一些最先进的方法的性能。与其它方法相比，我们的结果是好的。方法[57]使用两阶段、从粗到细的剖析，这显著地减少了计算时间，比任何实时应用所需的速度要慢。我们使用NVIDIA K20 GPU来训练我们的模型。
用于挑战的图像的平均坏死和非坏死像素分别为1330000和2900000。在测试时，使用我们的幻灯片窗口方法预测整个图像的分割的平均计算时间是这个GPU上的第二尺度。
我们添加了结肠数据集和多类分类场景，对脑肿瘤和结肠癌数据集上的几种方法进行了比较。性能总结在表4中。由于该算法的局限性，MCIL被排除在多类分类比较之外。在所有情况下，我们的方法（SVM CNN）产生统计上显著的结果。
对于GBM和LGG亚型的脑肿瘤分类，CNN特征比手动特征（MF）强大得多，并且性能提高了20.0%。与MCIL和TRANS相比，我们提出的框架分别提高了6.7%和9.1%。
对于结肠癌二值分类，我们的方法产生与脑肿瘤结果相似的最高性能，但是所有方法都达到至少90%的准确率。
在多方案中，只有我们的方法达到80%以上的精度。与其他方法相比，SVM-CNN在直接使用全图像时比SVM-IMG高出8.2%，而在使用硬编码手动特征的情况下比SVM-MF高出11.6%。令人惊讶的是，在结肠癌中，SVM IMG比SVM MF表现更好约4%。
在二值分类中，MCIL和SVM-CNN均取得了明显优于其他方法的性能。由于MCIL是基于多实例学习的算法，而我们的框架采用特征池技术，这与多实例学习类似，主要性能差异是由强大的CNN特征造成的。使用在一般图像数据库上训练的提取的特征使我们能够捕获复杂和抽象的模式，即使训练图像的数量有限。
为了更好地捕捉在我们的组织病理图像分析方法中激活了哪些特征，图像级热图（图。5和6）和特征斑块特征（图）。绘制了7和8）。它们在第3.4节中讨论。
分割结果
在MICCAI挑战中，我们最终的分割提交也以测试数据的84%的准确率获得了第一名。表5显示了其他参赛队的最高表现[ 28 ]。我们的框架比第二位的团队好11%。
表6总结了各种方法对脑肿瘤和结肠癌数据集的分割性能。GraphRLM不适合在这里进行比较，因为它是一种无监督的方法。对于脑肿瘤数据集，SVM-CNN比SVM-MF的性能提高了21.0%。使用微调美国有线电视新闻网进一步提高了0.4%的支持向量机CNMN。
对于结肠癌，基于CNN的方法显示出比SVM-MF至少16.2%的性能改进，因此结果显示与脑癌数据集类似的趋势。经过微调，精度进一步提高到94.8%，显示出1.6%的差别。此外，我们还提供了使用所有方法的分割结果的一些样本，如图所示。3和4分别为脑肿瘤和结肠癌数据集。
从表6中可以看出，使用基于CNN的特性而不是手动硬编码的特性可以观察到显著的性能差异。使用微调的CNN特征使结肠癌CNN特征的准确率提高了1%。这两种差异也可以通过这两个图来验证。3和4。对于GraphRLM，分割结果是不可理解的，或者没有提供分割结果。虽然GraphRLM的结果不能被精确地量化，但是在大多数情况下，它无法勾勒出有价值的边界，或者没有生成边界。即使在结肠癌中，GraphRLM也无法提供具有相似形态学模式的分段。另一方面，所有其他方法都达到至少64%的准确度。SVMCNN和SVM-FT在精度统计和可视化性能上都明显优于SVM-MF。
斑块大小的选择
在我们的分类框架中，20×放大倍数的采样斑块大小为336×336像素，40×放大倍数的采样斑块大小为672×672像素。我们还尝试了其他补丁大小，以探讨不同补丁大小的影响。结果如表7所示。从表7中的结果可以看出，672×672的补丁大小对二进制和多类分类任务都具有最高的精度。
在我们的分割框架中，选择了112×112像素的补丁大小。我们还探讨了补丁大小对我们的分割框架的影响。结果如表8所示。从结果来看，较小的补丁大小将导致两个数据集上更好的分割结果。这一事实符合我们的直觉。
在分割框架中，根据每个样本训练块与注释区域的重叠率，对每个样本训练块给出正负标签，并从所有样本训练块的预测标签中构造分割结果。在这种情况下，较大的斑块尺寸会影响分割区域边界的分辨率，从而影响分割结果的准确性。
美国有线电视新闻网活化特征可视化研究
我们提出的采用CNN特征的框架在脑肿瘤和结肠癌数据集上都显示出高精度。我们感兴趣的是我们的分类器从CNN特征中到底学到了什么，以及它们是否能够揭示生物学的见解。为此目的，在最后一个隐藏层（4096维）中的神经元反应的单个分量被可视化以观察CNN特征的特性。特别地，我们可以可视化他们的图像响应和特征响应，以了解CNN发现图像的哪个部分很重要。
在图像方面，利用线性SVM训练得到的分类模型，为每个补丁分配置信度。我们将每个贴图的置信分数可视化为热图（图）。5和6）。红色者蓝色）区域是，分类器将更有信心认为该区域是正的（resp.否定的）。HealMaPS有助于可视化分类器所考虑的重要区域。对于每个分类任务，本文显示了来自每个类别的一个图像。
图3脑肿瘤数据集的分割结果。原始图像。基底坏死（阳性）区掩盖灰色。其余的列显示c GraphRLM、d SVM-MF、e SVM-CNN和f SVM-FT方法的预测结果，其中真阳性、假阳性（错过）和假阴性（错误预测）区域分别被掩盖为紫色、淡红色和橙色。
在特征方面，我们将单个神经元在最后一个隐藏层中的反应可视化，以观察CNN特征的特征（图。7和8）。由分类SVM模型中的最高权重确定激活特征维数。对于相关的神经元，选择最激活它们的补丁（在该特征维度中具有最高值的补丁）。
图像级英雄
虽然我们没有明确地标记每种癌症类型的属性，但我们分类器的热图显示它们确实突出了有代表性的热点。例如，作为GBM特征的坏死区域通常被认为是高度阳性的。
对于脑肿瘤，照片显示在图中。5。我们有整体的所有幻灯片图像标记为GBM和LGG。在这个分类方案中，两个类别都是胶质瘤，但是具有不同的胶质瘤级别。高级胶质瘤包括间变性星形细胞瘤和多形性胶质母细胞瘤，它们伴随坏死区和增生性血管及巨核细胞的存在，并且可用H&E染色检测。在热图的例子中，GBM的内皮增生区域被很好地捕获。
对于结肠癌，二进制和多类分类的热图如图所示。6。在二元场景中，我们的CNN成功地识别了癌症病例中的畸形上皮细胞，以及在正常病例中均匀间隔的细胞结构。例如，在腺癌（AC）亚型的例子中，图中显示的大多数恶性导管元件由二进制分类器突出显示。对于图像的其余部分，基质细胞是丰富的，被认为是中性或正常的，因为它们在生物学上是良性的。正常例子中所示的腔部分被误分类为癌样区域，因为它类似于病状上皮细胞的形状。然而，二进制分类器忽略了每个癌症亚型的一些特定特征。
在粘液癌（MC）的例子中，分类器识别致密的上皮，但是忽略了MC的主要特征，在那里可以看到丰富的细胞外粘蛋白（原始图像中的淡紫色区域）。这是由于胶体与空白区域之间的相似性，这使得在二进制场景中更难识别。
图4结肠癌数据集的分割方法比较。原始图像。基底坏死（阳性）区掩盖灰色。其余的列显示了c GraphRLM、d SVM-MF、e SVM-CNN和f SVM-FT方法的预测结果，其中真阳性、假阳性（未命中）和假阴性（错误预测）区域分别被掩盖为紫色、淡红色和橙色。
在多类场景中，强调每个子类型的特定特征，并在它们的分类器热图中变得明显。在MC示例中，只有胶体部分触发MC分类器，其他恶性部分被抑制。利用分类器成功地捕获了锯齿状癌（SC）和乳头状癌（PC）的独特模式。在SC亚型中，不同于所有区域都被识别为恶性的情况，只有齿状上皮结构保持高度自信。在PC亚型中，只有细长的管状结构被突出显示。许多独特的SC模式被分类器忽略，因为它们类似于PC的管状特征。
对于筛状粉刺型腺癌（CCTA），其独特的筛状特征表现为频繁穿孔。对于AC亚型，分类器从二类到多类场景忽略了许多恶性导管元件，这是由于在所有癌症亚型中相似的普遍结构，这不利于提高性能。对于普通的例子，二值分类器和多类分类器显示一致的结果，而在多类中，图像中间的内腔部分被正确地抑制。
图5脑肿瘤GBM与LGG分类的热图。使用分类器为整个幻灯片图像的每个补丁分配置信度，该分类器形成热图。颜色为红色的区域更可能是GBM区域。这些热图的目的是说明整个幻灯片图像的哪一部分对分类器是重要的，并证明CNN特征的表达能力。在GBM的例子中，被认为是诊断GBM的基本形态学线索的内皮增生区域显示出高度的肯定信心。
为了比较美国有线电视新闻网的激活特征与其他特征，手工特征的版本也在图中示出。6。从这些数字中，我们可以清楚地看到美国有线电视新闻网激活特征的优势。
特征斑块特征
在从不同医学图像中提取出的CNN特征中，我们发现，单个特征维数可以表示一定的特征，这是应用CNN激活特征可视化时令人兴奋的发现之一。即使存在提供相同特征的某些类型的手动设计特征，CNN也能够从大型图像数据集中自动学习这些特征，而无需任何手动设计。由组织病理学家报道，一些特征可以传达临床见解，这也可以验证我们的发现从图像水平的热图分析。通过从具有最高权重的所有图像中选择块来可视化每个特征的特征。
关于脑肿瘤图像的更多细节，我们参考读者[ 19 ]。
对于结肠癌，二分类和多分类中最有区别的特征是可视化的，如图所示。7和8。与热图的发现类似，尽管我们没有提供关于任何病理特征的额外信息，但是分类器中具有高权重的特征对应于类别的特定特征。在二元分类中，重要的癌症特征包括腺癌(第一、第二、第四、第五和第六排)和乳头状瘤(第三排)；而重要的非癌症特征包括正常腺体(第一和第二排)、淋巴细胞簇(第三排)、出血(第四和第五排)和脂肪(第六排)。
多类分类器自动发现每个子类型更具体的特征，有些情况特别有趣且有潜在指导意义。
例如，CCTA特征不仅包含上述筛状结构（第二行），如预期，而且还包含一个在出血区域（第一行）激活的特征-表明CCTA与出血之间一些未被发现的相关性。
图6使用手动特征和CNN激活特征对结肠癌进行二分类和多分类的热图。类似于图5，基于每个补丁的置信度得分绘制热图，并且目的也是为了探索CNN特征的表达性。在二元分类（第二列和第四列）中，红色区域更可能是癌症。在多类分类(第3和第5列)中，仅示出了预测图像标签的分类器，即，对于AC图像，仅示出了AC-vs-rest分类器的预测。红色区域更可能是图像的标签。从二值分类到多类分类的过渡表明我们的多类分类器能够识别每个癌症亚型的特定特征。CNN特征和手动特征的比较表明，CNN特征比手动特征具有更强的表达能力。
许多CNN特征也提出了一些新的癌症组织分类标准。例如，PC的特征可以区分其特殊管状结构的顶部（第一行）和中部（第二行）。MC的特征似乎通过粘液密度将胶体分泌的斑块分开：第一排斑块的粘液比第二排多。这里为AC显示的两个特征看起来非常相似（两者都显示结肠导管的密集上皮衬里），并且可以识别为腺体结构。在CCTA斑块特征中，上述筛状结构（第一排）和出血（第二排）特征被激活，都是CCTA的典型特征。注意，尽管这里显示的出血斑块不属于结肠癌的性质，但它们仍然可以代表最后一个CNN隐匿层中的神经元，该隐匿层通常由出血的特征触发。对于正常类型，包含纵向和横向隐窝（肠腺，第一排）或基质细胞块（第二排）的特征被开启。
结论
本文介绍了利用ImageNet知识训练的深卷积激活特征，并将CNN模型应用于脑肿瘤和结肠癌数字组织病理学数据的特征提取。我们成功地将ImageNet知识作为深度卷积激活特征，以较少的训练数据对组织病理图像进行分类和分割。根据我们的实验，CNN特征明显优于手动特征。此外，由于单个组织病理学图像的尺寸很大，因此在分类框架中采用特征池技术构造单个图像级特征向量。
实验证明我们的框架在MICCAI脑肿瘤挑战中实现了97.5%的分类和84%的分割的最新结果。
后来，我们在结肠癌图像上应用这两个框架并取得了类似的成功，显示出与以往方法相比的显著改进。
图7用CNN激活特征的单个成分（神经元）选择的鉴别斑块样本。在二值分类任务中，每行补丁对来自所有结肠训练图像的4096个神经元中的一个产生高响应。选择每个分类器的6个顶部权重特征，并选择触发这6个神经元的顶部补丁来表示相应特征的特征。该图的目的是显示CNN特征的各个组成部分的特征，这些特征被二进制分类器认为是重要的。这些可视化特征传达了一些临床见解。
此外，由我们的分类器学习的特征产生生物学上有意义的洞察力，病理学家承认。联合地，从这些选定的斑块或区域的组织病理形态学将有助于病理学家发现具有生物学洞察力的模式。通过观察CNN激活特征神经元的鉴别斑块，可以发现相应亚型的组织成分。探索不同癌症分期和亚型的发展过程是有用的。通过应用数字组织病理图像分析，可以捕获和量化复杂形态学模式的细微差异，并且可以重新研究它们的关节相互作用，以反映患者的预后或药物反应，并提供细粒度的特征。
我们的动机是介绍一种通用的解决组织病理学问题的方法。这使得我们的设置比其他大多数简单得多。全卷积网络（FCN）[18]不适合对大规模图像进行分类。因此，我们不将我们的方法与FCN进行比较。在未来的工作中，我们将比较我们的方法与FCN的分割。
图8用CNN激活特征的单个成分（神经元）选择的鉴别斑块样本。在多类别分类任务中，每行补丁对来自所有结肠训练图像的4096个神经元中的一个产生高响应。为每个分类器选择两个顶部加权特征，并且选择触发这两个神经元的顶部补丁以表示相应特征的特征。该图的目的是显示CNN特征的各个组成部分的特征，这些特征被多类分类器认为是重要的。
这些可视化特征传达了一些临床见解。
缩写
AC：腺癌；CNN：卷积神经网络；CCTA：筛状昏迷型腺癌；GBM：多形性胶质母细胞瘤；KIRC：透明细胞肾癌；LGG：低度胶质瘤；MC：粘液癌；MCIL：多重聚类实例学习；MF：手动特征N：正常；PC：乳头y癌；RBM：限制性boltzmann机；SC：锯齿状癌；SVM：支持向量机；VLAD：局部聚集描述向量
致谢
我们感谢浙江大学病理学系提供结肠组织病理学图像和医学咨询。
我们还要感谢认知视觉团队提供他们的CNN模型。作者还感谢北航大学的邱自明帮助修改了手稿。
基金
这项工作得到了微软研究（EHealthProject）的支持；中国北京国家科学基金[授予4152033 ]；中国深圳技术创新委员会[授予SIFFAGA2016~627 ]；中国北京青年人才计划；T的基础研究基金。来自中国北航大学软件开发环境国家重点实验室的中国中央大学[批准SKLSDE-2015ZX-27]。
数据和材料的可用性
MICCAI 2014脑肿瘤数字病理学挑战数据集可在https://wiki.cancerimagingarchive.net/display/./MICCAI+2014+Grand+Challenges获得。Biaelja，它需要一个密码来访问数据。如果您想访问冒号数据集，请将密码发给本文的相应作者。
作者的贡献
ZJ和YX写了代码。L BW，YA和FZ进行了所有的实验。ML和E-CC提供了医学领域的支持。所有作者对算法设计的研究都做出了有价值的贡献。所有作者都参与撰写手稿。所有作者阅读并批准了最后的手稿。
竞争利益
作者宣称他们没有竞争利益。
同意出版
不适用。
伦理认同与参与同意
不适用。
出版商笔记
Springer Nature在公布的地图和机构附属机构中的管辖权主张方面保持中立。
作者详情
1、深圳市北航大学教育科研所软件开发环境国家重点实验室、生物力学与机械生物学重点实验室。2微软公司研究，北京，中国。清华大学跨学科信息科学研究所，北京，中国。台湾台北国立台湾大学生物医学电子与生物信息学研究所。
浙江大学医学院病理学系，杭州。
收到：2016年12月28日接受：2017年5月15日
参考文献1。
GurCAN Mn，Boucheron LE，A，Madabhushi A，RajPOOT NM，Yener B.
组织病理学图像分析TBME。2009；2 147—71。
Veta M，Pluim JPW，van Diest PJ，Viergever MA。乳腺癌病理组织学图像分析TBME。2014；61:1400—11。
Rastghalam R, Pourghassem H.基于mrf的可能纹理特征的乳腺癌检测和基于决策层融合的分类，使用hmm对热成像图像。模式恢复。2014；51:176—86。
通过融合到不同空间中的纹理特征的稀疏表示，对西红花I、鹿茸D、经济草G、Fotopoulos S.Hep-2细胞进行分类。模式恢复。2014；47∶23 67—78。
徐Y，莫T，冯Q，钟平，赖M，张EI-C。医学图像分析中特征表示的多实例深层学习。在：ICASSP。佛罗伦萨：IEEE；2014。第1626页-第30页。
李Y，王S，田Q，丁X。基于统计学习的目标检测的特征表示：综述。模式恢复。
2015；48∶3542 - 59。
Lilly.K, Lee DJ, Tippetts B, Archibald J.用于一般对象识别的特征构造方法。模式恢复。2013；46:3300 - 14。
Guo Y，Zhao G，PieTik。模式恢复。2012；45∶38 34 - 43。
Puig D，Garcia MA，Melendez J.独立于纹理分类的特征选择。模式恢复。2010；43:328—97。
10。Girshick R, Donahue J, Darrell T, Malik J.用于精确对象检测和语义分割的丰富特征层次。在：CVPR。
哥伦布：IEEE；2014。第580页-第7页。
11。龚Y，王L，郭R，拉泽布尼克S。深卷积活化特征的多尺度无序汇集。在：ECRV。苏黎世：Springer；2014。
第392页-第407页。
12。辛顿斯格，斯里瓦斯塔瓦N，Krizhevsky A，SuttSaveI，Salakhutdinov R.
通过防止特征检测器的自适应适应来改进神经网络。ARXIV预打印ARXIV：1207.0580。2012；1:1～8。
13。罗萨科夫斯基·O、邓·J、苏H、克劳斯·J、萨蒂什·S、马斯、黄兹、喀尔帕提·A、科斯拉·A、伯恩斯坦·M、伯格·AC、菲菲·L.Imagenet大规模视觉识别挑战。IJCV。2015；115（3）：211—52。
14。克里齐夫斯基A，SuttSaveI，辛顿葛。基于深度卷积神经网络的IMANET分类在：NIPS。Nestsf：NIPSF；2012。
第1097页-第105页。
15。塞尔特奥，Kong J，Shimada H，Catalyurek U，Saltz JH，古尔肯MN。
使用卷积神经网络学习和传输中层图像表示。在：CVPR。哥伦布：IEEE；2014。
第1717页-第24页。
16。谢里夫·拉扎维安·A，阿齐兹普尔·H，沙利文·J，卡尔森·S·Cnn的特色是现成的：一个惊人的识别基线。在：CVPR。哥伦布：IEEE；2014。第806页-第13页。
17。邓杰，董伟，苏格拉底，李LJ，李K，菲菲L。Imagenet：一个大型的分层图像数据库。在：CVPR。迈阿密：IEEE；2009。
第248页-第55页。
18。Long J，Shelhamer E，Darrell T。用于语义分割的全卷积网络。在：CVPR。波士顿：IEEE；2015。第3431页-第40页。
19。徐Y，贾Z，艾Y，张F，赖M，张EI-C。用于大规模脑肿瘤组织病理图像分类和分割的深卷积激活特征。在：ICASSP。布里斯班南部：IEEE；2015。
第947页-第51页。
20。Veta M，Pluim JPW，van Diest PJ，Viergever MA。乳腺癌病理组织学图像分析TBME。2014；61:1400—11。
Irshad H, Veillard A, Roux L, Racoceanu D.数字组织病理学中的核检测、分割和分类的方法：回顾现状和未来潜力。TBME。2014；7:97—114。
22。He L，Long LR，Antani S，Thoma GR。肿瘤检测和分级的组织学图像分析。计算机方法PROG生物医学。
2012；107:538—56。
23。Cruz Roa A，阿雷瓦罗奥瓦莱耶，Madabhushi A，冈萨雷斯奥索里奥FA。
一种用于图像表现、视觉可解释性和自动化基底细胞癌检测的深度学习体系。在：MICCAI。名古屋：斯普林格；2013。第403页-第10页。
24。Ciresan DC，Gi.A，Gambardella LM，Schmidhuber J.用深层神经网络检测乳腺癌组织学图像中的有丝分裂。在：MICCAI。
名古屋：斯普林格；2013。第411页-第8页。
25。MICCAI 2013对有丝分裂检测的重大挑战。2013。http://AMIDA13.ISI.UU.NL/。访问FEB 2016。
26。MICCAI 2014脑肿瘤数字病理学挑战。2014。http://wiki。
网络图像/显示/公开/MICCAI + 2014 + GRAM+挑战。访问FEB 2016。
27。MICCAI 2015腺分割挑战赛。2015。http://www2.warwick.ac.uk/fac/sci/dcs/./combi/././glascontest/.访问FEB 2016。
28。MICCAI 2014脑肿瘤数字病理学挑战提交网站。2014。http://PAI.BMI。访问FEB 2016。
29。黄钰，李。基于分形分析的病理性前列腺图像自动分类。TMI。2009；28∶1037—50。
30。张H，Borowsky A，Spellman P，Parvin B。通过形态计量学上下文对肿瘤组织学分类。在：CVPR。波特兰：IEEE；2013。
第2203页-第10页。
31。孔杰，塞特尔O，Shimada H，Boyer KL，Saltz JH，古尔肯MN。
神经母细胞瘤全切片组织学图像计算机辅助评价：神经母细胞分化分级。模式恢复。
2009；4:1080- 92。
32。Tosun AB, Gunduz-Demir C.用于组织病理图像分割的图形游程矩阵。TMI。2011；30:721—32。
33。Kalkan H，Nap M，Duin RPW，Loog M。用于全切片组织病理学的结直肠癌自动诊断。在：MICCAI。尼斯：斯普林格：2012。
第550页-第7页。
34。Kalkan H，Nap M，Duin RPW，Loog M。结肠组织病理学局部斑块的自动分类。在：ICPR。筑波科学城：IEEE；2012。第61页-第4页。
许等。BMC生物信息学（2017）18:28
第17页第17页
35。Chang H, Nayak N, Spellman PT, Parvin B.通过预测性稀疏分解和空间金字塔匹配的组织病理学特征。在：MICCAI。名古屋：斯普林格；2013。第91页-第8页。
36。Rashid S，Fazli L，博格A，西门子R，Abolmaesumi P，Salcudean SE。
前列腺腺癌良、恶性腺体的分离
在：MICCAI。名古屋：斯普林格；2013。第461页-第8页。
37。宋Y，蔡，休，Chen M，卡纳德T，周Y，Feng D.
用于图像特征提取和分类的判别式数据变换。在：MICCAI。名古屋：斯普林格；2013。第452页-第9页。
38。火花R，Madabhushi A。显性形状描述符：组织病理分类的新的形态学特征。米娅。2013；17:997—1009。
39。Mosquera-Lopez C, Agaian S, Velez-Hoyos A.使用新的组织描述符对前列腺癌进行自动分级的多阶段学习方案的开发。在：ICASSP。佛罗伦萨：IEEE；2014。
第3586页-第90页。
40。Le QV，Han J，Gray JW，Spellman PT，Borowsky A，Parvin B。学习肿瘤特征的不变性。在：ISBI。巴塞罗那：IEEE；2012。
第302页-第5页。
41。Nayak N, Chang H, Borowsky A, Spellman P, Parvin B.通过稀疏特征学习的肿瘤组织病理学分类。在：ISBI。旧金山：IEEE；2013。
第410页-第3页。
42。Donahue J，贾伊，维纳斯O，Hoffman J，Zhang N，Tzeng E，Darrell T.
DECAF：一种用于一般视觉识别的深度卷积激活特征。ICML。北京：IMLS；2014，第647页-第55页。
43。Sermanet P, Eigen D, Zhang X, Mathieu M, Fergus R, LeCuY. Overfeat:使用卷积网络的集成识别、定位和检测。ARXIV预打印ARXIV：1312.6229。2013；1:1～16。
44。Cruz-Roaa A, Arevaloa J, Madabhushib A, Gonzleza F.用于图像表示、视觉解释和自动化基底细胞癌检测的深度学习架构。在：MICCAI。名古屋：斯普林格；2013。第403页-第10页。
45。Girshick R, Donahue J, Darrell T, Malik J.用于精确对象检测和语义分割的丰富特征层次。在：CVPR。
哥伦布：IEEE；2014。第580页-第7页。
46。张N，Donahue J，Girshick R，Darrell T。用于细粒度类别检测的基于部件的r-cnns。在：ECRV。苏黎世：Springer；2014。
第834页-第49页。
47。徐Y，朱JY，张E，屠Z。组织病理学肿瘤图像分类、分割和聚类的多聚类实例学习。
在：CVPR。普罗维登斯：IEEE；2012。第964页-第71页。
48。徐Y，朱JY，张EI-C，赖M，屠Z。组织病理学薄弱的癌症图像分割和分类。米娅。2014；18:591—604。
49。徐Y，张J，Eric IC，Lai M，Tu Z。用于组织病理图像分割的上下文约束多实例学习。在：MICCAI。
尼斯：斯普林格：2012。第623页-第30页。
50。Gorelick L、Veksler O、Gaed M、G·MEZ、JA、Moussa M、Bauman G、芬斯塔A、Ward AD.前列腺组织病理学：学习组织成分直方图用于癌症检测和分类。TMI。2013；32∶1804—18。
51。Kandemirl M，张C，汉普雷特FA。通过细胞图增强多实例病理组织学癌症诊断。在：MICCAI。波士顿：斯普林格；2014。第228页-第35页。
52。Boureau YL，Ponce J，Lecun Y。视觉识别中特征池的理论分析。在：ICML。海法：IMLS；2010。第111页-第8页。
53。Khan AM，Rajpoot N，Treanor D，Magee D。使用图像特异性颜色反卷积的数字组织病理图像中的染色标准化的非线性映射方法。TBME。2014；61:1729—38。
54。Zhu Y，Zhang S，Liu W，Meta通过主动学习的可扩展病理组织学图像分析。在：MICCAI。波士顿：斯普林格；2014。第369页-第76页。
55。金斯堡S，阿里·S，乔治·李·AB，马达胡希·A。非线性核中的可变重要性：数字化组织病理学的分类。在：MICCAI。名古屋：斯普林格；2013。第238页-第45页。
56。范雷，Chang KW，Hsieh CJ，Wang XR，Lin CJ。线性的：用于大型线性分类的图书馆。J马赫学习RS. 2008；9:1871- 4。
57。Barker J，Hoogi A，DePurangeA，Ruin DL。利用局部代表性平片对全切片数字病理图像中脑肿瘤类型进行自动分类。医学图像肛门。2016；30:60- 71。
58。曼尼凡南S，沈，Li W，安努齐亚塔R，哈马德H，王R，Zhang J.
利用局部共生特征和条件随机场进行脑肿瘤区域分割。技术报告。2014。
把你的下一份手稿提交给生物医学中心，我们将在每一步都帮助你：
